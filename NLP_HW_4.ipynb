{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework #4  Bodie Franklin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import nltk\n",
    "import matplotlib as plt\n",
    "from difflib import SequenceMatcher\n",
    "import os\n",
    "import editdistance\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import requests\n",
    "import urllib.request\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before parts of speech: For a long time Pierre could not understand, but when he did, he jumped up from the sofa, seized Boris under the elbow in his quick, clumsy way, and, blushing far more than Boris, began to speak with a feeling of mingled shame and vexatio\n",
      "---------------------------------------------------------------------\n",
      "Parts of Speech: [('For', 'IN'), ('a', 'DT'), ('long', 'JJ'), ('time', 'NN'), ('Pierre', 'NNP'), ('could', 'MD'), ('not', 'RB'), ('understand', 'VB'), (',', ','), ('but', 'CC'), ('when', 'WRB'), ('he', 'PRP'), ('did', 'VBD'), (',', ','), ('he', 'PRP'), ('jumped', 'VBD'), ('up', 'RP'), ('from', 'IN'), ('the', 'DT'), ('sofa', 'NN'), (',', ','), ('seized', 'VBN'), ('Boris', 'NNP'), ('under', 'IN'), ('the', 'DT'), ('elbow', 'NN'), ('in', 'IN'), ('his', 'PRP$'), ('quick', 'NN'), (',', ','), ('clumsy', 'JJ'), ('way', 'NN'), (',', ','), ('and', 'CC'), (',', ','), ('blushing', 'VBG'), ('far', 'RB'), ('more', 'JJR'), ('than', 'IN'), ('Boris', 'NNP'), (',', ','), ('began', 'VBD'), ('to', 'TO'), ('speak', 'VB'), ('with', 'IN'), ('a', 'DT'), ('feeling', 'NN'), ('of', 'IN'), ('mingled', 'JJ'), ('shame', 'NN'), ('and', 'CC'), ('vexatio', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "long_sentence = \"For a long time Pierre could not understand, but when he did, he jumped up from the sofa, seized Boris under the elbow in his quick, clumsy way, and, blushing far more than Boris, began to speak with a feeling of mingled shame and vexatio\"\n",
    "\n",
    "print(\"Before parts of speech:\", long_sentence)\n",
    "\n",
    "\n",
    "\n",
    "tokens = nltk.word_tokenize(long_sentence)\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(\"Parts of Speech:\",nltk.pos_tag(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before parts of Speech: For a long time I had no regular lessons.\n",
      "---------------------------------------------------------------------\n",
      "Parts of Speech: [('F', 'NNP'), ('o', 'MD'), ('r', 'VB'), (' ', 'VB'), ('a', 'DT'), (' ', 'JJ'), ('l', 'NN'), ('o', 'NN'), ('n', 'JJ'), ('g', 'NN'), (' ', 'NNP'), ('t', 'NN'), ('i', 'NN'), ('m', 'VBP'), ('e', 'NN'), (' ', 'NN'), ('I', 'PRP'), (' ', 'VBP'), ('h', 'PDT'), ('a', 'DT'), ('d', 'NN'), (' ', 'NNP'), ('n', 'CC'), ('o', 'JJ'), (' ', 'NNP'), ('r', 'NN'), ('e', 'NN'), ('g', 'NN'), ('u', 'JJ'), ('l', 'NN'), ('a', 'DT'), ('r', 'NN'), (' ', 'NNP'), ('l', 'NN'), ('e', 'NN'), ('s', 'NN'), ('s', 'NN'), ('o', 'NN'), ('n', 'JJ'), ('s', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "Short_sentence = \"For a long time I had no regular lessons.\"\n",
    "\n",
    "print(\"Before parts of Speech:\", Short_sentence)\n",
    "\n",
    "\n",
    "\n",
    "tokens = nltk.word_tokenize(Short_sentence)\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "print(\"Parts of Speech:\",nltk.pos_tag(Short_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe POS tagger doesn't work well on short sentence because the tagger is breaking up each word and trying to classify each letter\n",
    "instead of the word as part of speech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For          ADP        IN       conjunction, subordinating or preposition\n",
      "a            DET        DT       determiner\n",
      "long         ADJ        JJ       adjective\n",
      "time         NOUN       NN       noun, singular or mass\n",
      "Pierre       PROPN      NNP      noun, proper singular\n",
      "could        AUX        MD       verb, modal auxiliary\n",
      "not          PART       RB       adverb\n",
      "understand   VERB       VB       verb, base form\n",
      ",            PUNCT      ,        punctuation mark, comma\n",
      "but          CCONJ      CC       conjunction, coordinating\n",
      "when         ADV        WRB      wh-adverb\n",
      "he           PRON       PRP      pronoun, personal\n",
      "did          VERB       VBD      verb, past tense\n",
      ",            PUNCT      ,        punctuation mark, comma\n",
      "he           PRON       PRP      pronoun, personal\n",
      "jumped       VERB       VBD      verb, past tense\n",
      "up           ADP        RP       adverb, particle\n",
      "from         ADP        IN       conjunction, subordinating or preposition\n",
      "the          DET        DT       determiner\n",
      "sofa         NOUN       NN       noun, singular or mass\n",
      ",            PUNCT      ,        punctuation mark, comma\n",
      "seized       VERB       VBD      verb, past tense\n",
      "Boris        PROPN      NNP      noun, proper singular\n",
      "under        ADP        IN       conjunction, subordinating or preposition\n",
      "the          DET        DT       determiner\n",
      "elbow        NOUN       NN       noun, singular or mass\n",
      "in           ADP        IN       conjunction, subordinating or preposition\n",
      "his          PRON       PRP$     pronoun, possessive\n",
      "quick        ADJ        JJ       adjective\n",
      ",            PUNCT      ,        punctuation mark, comma\n",
      "clumsy       ADJ        JJ       adjective\n",
      "way          NOUN       NN       noun, singular or mass\n",
      ",            PUNCT      ,        punctuation mark, comma\n",
      "and          CCONJ      CC       conjunction, coordinating\n",
      ",            PUNCT      ,        punctuation mark, comma\n",
      "blushing     VERB       VBG      verb, gerund or present participle\n",
      "far          ADV        RB       adverb\n",
      "more         ADJ        JJR      adjective, comparative\n",
      "than         SCONJ      IN       conjunction, subordinating or preposition\n",
      "Boris        PROPN      NNP      noun, proper singular\n",
      ",            PUNCT      ,        punctuation mark, comma\n",
      "began        VERB       VBD      verb, past tense\n",
      "to           PART       TO       infinitival \"to\"\n",
      "speak        VERB       VB       verb, base form\n",
      "with         ADP        IN       conjunction, subordinating or preposition\n",
      "a            DET        DT       determiner\n",
      "feeling      NOUN       NN       noun, singular or mass\n",
      "of           ADP        IN       conjunction, subordinating or preposition\n",
      "mingled      VERB       VBN      verb, past participle\n",
      "shame        NOUN       NN       noun, singular or mass\n",
      "and          CCONJ      CC       conjunction, coordinating\n",
      "vexatio      NOUN       NN       noun, singular or mass\n",
      "-----------------------------------------------------------------------------\n",
      "For          ADP        IN       conjunction, subordinating or preposition\n",
      "a            DET        DT       determiner\n",
      "long         ADJ        JJ       adjective\n",
      "time         NOUN       NN       noun, singular or mass\n",
      "I            PRON       PRP      pronoun, personal\n",
      "had          VERB       VBD      verb, past tense\n",
      "no           DET        DT       determiner\n",
      "regular      ADJ        JJ       adjective\n",
      "lessons      NOUN       NNS      noun, plural\n",
      ".            PUNCT      .        punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "#import en_core_web_sm\n",
    "\n",
    "#nlp = en_core_web_sm.load()\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "long_sp = nlp(long_sentence)\n",
    "\n",
    "short_sp = nlp(Short_sentence)\n",
    "\n",
    "\n",
    "for word in long_sp:\n",
    "    print(f'{word.text:{12}} {word.pos_:{10}} {word.tag_:{8}} {spacy.explain(word.tag_)}')\n",
    "    \n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "for word in short_sp:\n",
    "    print(f'{word.text:{12}} {word.pos_:{10}} {word.tag_:{8}} {spacy.explain(word.tag_)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2nd POS tagger seems to do a better job at the tagging than the first tagger. The first tagger was breaking up each\n",
    "word into letters than describing them as POS. But the 2nd seems to do a better job of classifying the words with context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Related has and will continue to fully comply with all existing government regulations for developing within the zone\n",
      "---------------------------------------------------------------------\n",
      "Related VBD\n",
      "has VB\n",
      "and CC\n",
      "will VB\n",
      "continue VB\n",
      "to to\n",
      "fully JJ\n",
      "comply VB\n",
      "with DT\n",
      "all CC\n",
      "existing VB\n",
      "government NN\n",
      "regulations NN\n",
      "for RB\n",
      "developing VB\n",
      "within MD\n",
      "the RP\n",
      "zone NN\n"
     ]
    }
   ],
   "source": [
    "news_sentence = \"Related has and will continue to fully comply with all existing government regulations for developing within the zone\"\n",
    "print(news_sentence)\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "\n",
    "print('Related' ,'VBD')\n",
    "print('has' ,'VB')\n",
    "print('and' ,'CC')\n",
    "print('will' ,'VB')\n",
    "print('continue' ,'VB')\n",
    "print('to' ,'to')\n",
    "print('fully' ,'JJ')\n",
    "print('comply' ,'VB')\n",
    "print('with' ,'DT')\n",
    "print('all' ,'CC')\n",
    "print('existing' ,'VB')\n",
    "print('government' ,'NN')\n",
    "print('regulations' ,'NN')\n",
    "print('for' ,'RB')\n",
    "print('developing' ,'VB')\n",
    "print('within' ,'MD')\n",
    "print('the' ,'RP')\n",
    "print('zone' ,'NN')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parts of Speech: [('Related', 'VBN'), ('has', 'VBZ'), ('and', 'CC'), ('will', 'MD'), ('continue', 'VB'), ('to', 'TO'), ('fully', 'RB'), ('comply', 'VB'), ('with', 'IN'), ('all', 'DT'), ('existing', 'VBG'), ('government', 'NN'), ('regulations', 'NNS'), ('for', 'IN'), ('developing', 'VBG'), ('within', 'IN'), ('the', 'DT'), ('zone', 'NN')]\n",
      "---------------------------------------------------------------------\n",
      "Related      VERB       VBN      verb, past participle\n",
      "has          VERB       VBZ      verb, 3rd person singular present\n",
      "and          CCONJ      CC       conjunction, coordinating\n",
      "will         AUX        MD       verb, modal auxiliary\n",
      "continue     VERB       VB       verb, base form\n",
      "to           PART       TO       infinitival \"to\"\n",
      "fully        ADV        RB       adverb\n",
      "comply       VERB       VB       verb, base form\n",
      "with         ADP        IN       conjunction, subordinating or preposition\n",
      "all          DET        DT       determiner\n",
      "existing     VERB       VBG      verb, gerund or present participle\n",
      "government   NOUN       NN       noun, singular or mass\n",
      "regulations  NOUN       NNS      noun, plural\n",
      "for          ADP        IN       conjunction, subordinating or preposition\n",
      "developing   VERB       VBG      verb, gerund or present participle\n",
      "within       ADP        IN       conjunction, subordinating or preposition\n",
      "the          DET        DT       determiner\n",
      "zone         NOUN       NN       noun, singular or mass\n"
     ]
    }
   ],
   "source": [
    "tokens = nltk.word_tokenize(news_sentence)\n",
    "print(\"Parts of Speech:\",nltk.pos_tag(tokens))\n",
    "\n",
    "print(\"---------------------------------------------------------------------\")\n",
    "\n",
    "news_sp = nlp(news_sentence)\n",
    "\n",
    "\n",
    "for word in news_sp:\n",
    "    print(f'{word.text:{12}} {word.pos_:{10}} {word.tag_:{8}} {spacy.explain(word.tag_)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the taggers tagged the news sentence exaclty the same.  My manual tagging was signfnicantly different from both taggers.\n",
    "My explaination is that grammar has never been my strong suite, therefore I would imagine a computer would out perform me. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
